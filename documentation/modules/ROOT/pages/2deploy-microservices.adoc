= Deploy Microservices
include::_attributes.adoc[]

[#deploycustomer]
## Deploy customer

创建 tutorial namespace 

[source,bash]
----
kubectl create namespace tutorial
kubectl config set-context $(kubectl config current-context) --namespace=tutorial
----

克隆源代码

[source,bash]
----
git clone https://github.com/redhat-developer-demos/istio-tutorial
cd istio-tutorial
----

### 构建 docker 镜像

NOTE: Your very first Docker build will take a bit of time as it downloads all the layers. Subsequent rebuilds of the Docker image, updating only the microservice layer will be very fast.

[source,bash]
----
cd customer/java/springboot
mvn clean package
docker build -t docker build -t kuopsme/reahat.istio.customer .
docker images | grep reahat.istio.customer
----

Now let's deploy the customer pod with its sidecar

[source,bash,subs="+macros,+attributes"]
----
kubectl apply -f <(istioctl kube-inject -f link:{github-repo}/{customer-repo}/kubernetes/Deployment.yml[../../kubernetes/Deployment.yml]) -n tutorial
kubectl create -f link:{github-repo}/{customer-repo}/kubernetes/Service.yml[../../kubernetes/Service.yml] -n tutorial
----

=== Expose customer

Since the `customer` service is the one our users will interact with, let's add an OpenShift Route that exposes that endpoint.

[source,bash]
----
oc expose service customer -n tutorial

oc get route -n tutorial
oc get pods -w -n tutorial

or

kubectl get route -o=jsonpath='{.items[0].spec.host}'
kubectl get pods -w
----

IMPORTANT: If your pod fails with `ImagePullBackOff`, it's possible that your current terminal isn't using the proper Docker Environment. See link:#setup-environment[Setup environment].

Wait until the status is `Running` and there are `2/2` pods in the `Ready` column. To exit, press `Ctrl+C`

Then test the customer endpoint

[source,bash]
----
curl customer-tutorial.$(minishift ip).nip.io
----

You should see the following error because the services `preference` and `recommendation` are not yet deployed.

----
customer => I/O error on GET request for "http://preference:8080": preference; nested exception is java.net.UnknownHostException: preference
----

Also review the logs

[source,bash]
----
stern $(kubectl get pods|grep customer|awk '{ print $1 }'|head -1) -c customer
----

You should see a stacktrace containing this cause:

[source,bash]
----
org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://preference:8080": preference; nested exception is java.net.UnknownHostException: preference
----

Back to the main istio-tutorial directory

[source,bash]
----
cd ../../..
----

[#deploypreference]
== Deploy preference

=== Preference build using Docker daemon

[source,bash,subs="+macros,+attributes"]
----
cd preference/java/springboot
mvn clean package
docker build -t example/preference:v1 .
docker images | grep preference

oc apply -f <(istioctl kube-inject -f link:{github-repo}/{preference-repo}/kubernetes/Deployment.yml[../../kubernetes/Deployment.yml]) -n tutorial
oc create -f link:{github-repo}/{preference-repo}/kubernetes/Service.yml[../../kubernetes/Service.yml]

or

kubectl apply -f <(istioctl kube-inject -f link:{github-repo}/{preference-repo}/kubernetes/Deployment.yml[../../kubernetes/Deployment.yml]) -n tutorial
kubectl create -f link:{github-repo}/{preference-repo}/kubernetes/Service.yml[../../kubernetes/Service.yml]
----

=== Preference build using OpenShift S2I strategy

[source, bash]
----
cd preference/java/springboot
oc new-app -l app=preference,version=v1 --name=preference-v1 --context-dir=preference/java/springboot -e JAEGER_SERVICE_NAME=preference JAEGER_ENDPOINT=http://jaeger-collector.istio-system.svc:14268/api/traces JAEGER_PROPAGATION=b3 JAEGER_SAMPLER_TYPE=const JAEGER_SAMPLER_PARAM=1 JAVA_OPTIONS='-Xms128m -Xmx256m -Djava.net.preferIPv4Stack=true' fabric8/s2i-java~https://github.com/redhat-developer-demos/istio-tutorial -o yaml  > preference.yml
oc apply -f <(istioctl kube-inject -f preference.yml) -n tutorial
oc delete svc/preference-v1 -n tutorial; oc create -f ../../kubernetes/Service.yml -n tutorial
oc logs bc/preference-v1 -f -n tutorial
----

=== Wait preference to be deployed

[source, bash]
----
oc get pods -w -n tutorial
or
kubectl get pods -w
----

Wait until the status is `Running` and there are `2/2` pods in the `Ready` column. To exit, press `Ctrl+C`

[source,bash]
----
curl customer-tutorial.$(minishift ip).nip.io
----

It will respond with an error since the service `recommendation` is not yet deployed.

NOTE: We could make this a bit more resilient in a future iteration of this tutorial

[source,bash]
----
customer => 503 preference => I/O error on GET request for "http://recommendation:8080": recommendation; nested exception is java.net.UnknownHostException: recommendation
----

and check out the logs

[source,bash]
----
stern $(kubectl get pods|grep preference|awk '{ print $1 }'|head -1) -c preference
----

You should see a stacktrace containing this cause:

[source,bash]
----
org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://recommendation:8080": recommendation; nested exception is java.net.UnknownHostException: recommendation
----

Back to the main istio-tutorial directory

[source,bash]
----
cd ../../..
----

[#deployrecommendation]
== Deploy recommendation

IMPORTANT: The tag `v1` at the end of the image name matters. We will be creating a `v2` version of `recommendation` later in this tutorial. Having both a `v1` and `v2` version of the `recommendation` code will allow us to exercise some interesting aspects of Istio's capabilities.

=== Recommendation build using Docker daemon

[source,bash,subs="+macros,+attributes"]
----
cd recommendation/java/vertx
mvn clean package
docker build -t example/recommendation:v1 .
docker images | grep recommendation

oc apply -f <(istioctl kube-inject -f link:{github-repo}/{recommendation-repo}/kubernetes/Deployment.yml[../../kubernetes/Deployment.yml]) -n tutorial
oc create -f link:{github-repo}/{recommendation-repo}/kubernetes/Service.yml[../../kubernetes/Service.yml] -n tutorial
oc get pods -w

or 

kubectl apply -f <(istioctl kube-inject -f link:{github-repo}/{recommendation-repo}/kubernetes/Deployment.yml[../../kubernetes/Deployment.yml]) -n tutorial
kubectl create -f link:{github-repo}/{recommendation-repo}/kubernetes/Service.yml[../../kubernetes/Service.yml]
kubectl get pods -w
----

=== Recommendation build using OpenShift S2I strategy

[source, bash]
----
cd recommendation/java/vertx
oc new-app -l app=recommendation,version=v1 --name=recommendation-v1 --context-dir=recommendation/java/vertx JAVA_OPTIONS='-Xms128m -Xmx256m -Djava.net.preferIPv4Stack=true' fabric8/s2i-java~https://github.com/redhat-developer-demos/istio-tutorial -o yaml  > recommendation.yml
oc apply -f <(istioctl kube-inject -f recommendation.yml) -n tutorial
oc delete svc/recommendation-v1 -n tutorial; oc create -f ../../kubernetes/Service.yml -n tutorial
oc logs bc/recommendation-v1 -f -n tutorial
----

=== Wait recommendation to be deployed

Wait until the status is `Running` and there are `2/2` pods in the `Ready` column. To exit, press `Ctrl+C`

[source,bash]
----
curl customer-tutorial.$(minishift ip).nip.io
----

it should now return

[source,bash]
----
customer => preference => recommendation v1 from '99634814-sf4cl': 1
----

and you can monitor the `recommendation` logs with

[source,bash]
----
stern $(kubectl get pods|grep recommendation-v1|awk '{ print $1 }'|head -1) -c recommendation
----

Back to the main `istio-tutorial` directory

[source,bash]
----
cd ../../..
----

[#redeployingcode]
== Updating Redeploying Code

When you wish to change code (e.g. editing the .java files) and wish to "redeploy", simply:

[source,bash]
----
cd {servicename}/java/{springboot|vertx}

vi src/main/java/com/redhat/developer/demos/{servicename}/{Servicename}{Controller|Verticle}.java
----

Make your changes, save it and then:

[source,bash]
----
mvn clean package
docker build -t example/{servicename}:v1 .

oc get pods -o jsonpath='{.items[*].metadata.name}' -l app={servicename}
oc get pods -o jsonpath='{.items[*].metadata.name}' -l app={servicename},version=v1
oc delete pod -l app={servicename},version=v1

or

kubectl get pods -o jsonpath='{.items[*].metadata.name}' -l app={servicename}
kubectl get pods -o jsonpath='{.items[*].metadata.name}' -l app={servicename},version=v1
kubectl delete pod -l app={servicename},version=v1
----

Why the delete pod?

Based on the Deployment configuration, Kubernetes/OpenShift will recreate the pod, based on the new docker image as it attempts to keep the desired replicas available

[source,bash]
----
oc describe deployment {servicename} | grep Replicas
or
kubectl describe deployment {servicename} | grep Replicas
----
